{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データソース"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## webサイト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語  \n",
    "http://www.data.go.jp/  \n",
    "http://linkdata.org/  \n",
    "http://aws.amazon.com/public-data-sets/  \n",
    "http://www.google.com/publicdata/directory  \n",
    "http://www.e-stat.go.jp/SG1/estat/eStatTopPortal.do  \n",
    "\n",
    "英語  \n",
    "http://www.data.gov/  \n",
    "https://www.kaggle.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 適当なサンプル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.zeros(5)\n",
    "np.ones((5,5))\n",
    "np.empty((3,4))\n",
    "np.eye(5)\n",
    "np.arange(5, 50, 2)\n",
    "np.arange(9).reshape((3,3))\n",
    "np.random.randn(10, 10)\n",
    "np.random.permutation(4)\n",
    "np.random.randint(0, 5, size=10)\n",
    "np.random.seed(12345) # ランダムシード\n",
    "dframe = DataFrame(np.random.randn(5*5).reshape((5,5)),index=['A','B','D','E','F'],columns=['col1','col2','col3','col4','col5'])\n",
    "\n",
    "from scipy import stats\n",
    "stats.norm(0,5).rvs(100)\n",
    "# 正規分布に従う乱数です。\n",
    "data1 = stats.norm(0, 5).rvs(100)\n",
    "# γ分布に従う乱数を生成します。\n",
    "data2 = np.concatenate([stats.gamma(5).rvs(50) - 1, - 1 * stats.gamma(5).rvs(50)])\n",
    "\n",
    "N = 500\n",
    "X = np.random.uniform(low=0, high=1, size=[N,2])\n",
    "X = np.random.uniform(low=-1, high=1, size=(1000,2)) * (2,1)\n",
    "y = np.random.choice([0,1], size=N)\n",
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "s = np.random.normal(mu, sigma, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用意されているデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.load_dataset(\"tips\")\n",
    "sns.load_dataset('flights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "print(data.DESCR)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "# MNISTの場合，60000が学習，10000がテスト，と決まっている\n",
    "# http://yann.lecun.com/exdb/mnist/\n",
    "X_train = mnist.data[:60000]\n",
    "X_test  = mnist.data[60000:70000]\n",
    "y_train = mnist.target[:60000]\n",
    "y_test  = mnist.target[60000:70000]\n",
    "\n",
    "from sklearn.datasets import load_sample_image\n",
    "china = load_sample_image('china.jpg')\n",
    "plt.imshow(china);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファイルを指定してダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "# データのダウンロード\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", \"allice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Webからデータを取得するために、requestsをインポートします。\n",
    "import requests\n",
    "# CSVデータのために、StringIOをつかいます。\n",
    "from io import StringIO\n",
    "# データのURLです。\n",
    "url = \"http://elections.huffingtonpost.com/pollster/2012-general-election-romney-vs-obama.csv\"\n",
    "# requestsをつかってデータをtextとして取得します。\n",
    "source = requests.get(url).text\n",
    "# StringIOを使ってpandasのエラーを防ぎます。\n",
    "poll_data = StringIO(source) \n",
    "poll_df = pd.read_csv(poll_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://qiita.com/HirofumiYashima/items/50d56ba229c364ae4960\n",
    "# !conda install pandas-datareader\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "prices = web.DataReader(['CVX','XOM','BP'], 'yahoo', \n",
    "                               start=datetime.datetime(2010, 1, 1), \n",
    "                               end=datetime.datetime(2013, 1, 1))['Adj Close']\n",
    "\n",
    "\n",
    "# 所謂ハイテク企業の株価を扱ってみます。\n",
    "tech_list = ['AAPL','GOOG','MSFT','AMZN']\n",
    "# 直近1年間のデータを使ってみましょう。\n",
    "end = datetime.datetime.now()\n",
    "start = datetime.datetime(end.year - 1,end.month,end.day)\n",
    "# それぞれの企業ごとに、Yahooのサイトからデータを取得します\n",
    "for stock in tech_list:   \n",
    "    # それぞれの名前でDataFrameを作ります。\n",
    "    globals()[stock] = web.DataReader(stock,'yahoo',start, end)\n",
    "\n",
    "# 各社の'Adj Close'をデータフレームでまとめる。\n",
    "closing_df = web.DataReader(['AAPL','GOOG','MSFT','AMZN'],'yahoo',start,end)['Adj Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクレイピングは最後の手段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web上のテーブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pip install beautiful-soup\n",
    "#pip install html5lib\n",
    "import pandas as pd\n",
    "url = 'http://www.fdic.gov/bank/individual/failed/banklist.html'\n",
    "dframe_list = pd.io.html.read_html(url)\n",
    "dframe_list[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
